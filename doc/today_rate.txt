"X1" "X2" "X3"
"PreD" "1" "2" "3"
"XLK*" "0.10" "0.12" "0.14"
"XLF*" "0.03" "0.03" "0.02"
"XLE*" "0.07" "0.05" "0.18"
"XLB-" "0.05" "0.04" "0.05"
"XLI-" "0.05" "0.02" "0.04"
"XLY-" "0.16" "0.31" "0.24"
"XLV*" "0.03" "0.02" "0.02"
"XLP-" "0.07" "0.06" "0.03"
"XLU-" "0.07" "0.07" "0.13"
"TLT*" "0.05" "0.04" "0.05"
"zero" "0.31" "0.25" "0.10"

Tech XLK x3= TECL
Fin  XLF x3= FAS
Ind  XLI
Bas  XLB
Cons XLY
Ene  XLE x2= ERX
Heal XLV x3= CURE
Util XLU
Stap XLP
Trea TLT x3= TMF
SPSh SH x3=SPXS
Zero zero
# Note: Sell fast Leveraged ETFs. It must decay in a long term.
# Pre: 19:00-22:30/20:00-23:30, EST 06:00-09:30.
# Market: 22:30-05:00/23:30-06:00, EST 09:30-16:00.
# After: 05:00-09:00/06:00-10:00, EST 16:00-20:00.

START: 2024-12-28 22:44:38
END: 2024-12-28 23:17:36
MIN DATE: 2006-12-01
MAX DATE: 2024-12-27
DIM: 4548x4445
===1 days===
AUC: 0.974624835439627
Accuracy: 0.707279524961513
eta : c(0.05, 0.05, 0.05)
max_depth : c(4, 6, 8)
gamma : c(0, 0, 0)
colsample_bytree : c(0.4, 0.4, 0.4)
min_child_weight : c(1, 1, 1)
subsample : c(1, 1, 1)
nrounds : c(100, 100, 100)
logLoss : c(2.4, 2.4, 2.4)
logLossSD : c(NA, NA, NA)
nrounds : 100
max_depth : 4
eta : 0.05
gamma : 0
colsample_bytree : 0.4
min_child_weight : 1
subsample : 1
===2 days===
AUC: 0.980200420701237
Accuracy: 0.745270567531896
eta : c(0.05, 0.05, 0.05)
max_depth : c(4, 6, 8)
gamma : c(0, 0, 0)
colsample_bytree : c(0.4, 0.4, 0.4)
min_child_weight : c(1, 1, 1)
subsample : c(1, 1, 1)
nrounds : c(100, 100, 100)
logLoss : c(2.4, 2.4, 2.4)
logLossSD : c(NA, NA, NA)
nrounds : 100
max_depth : 4
eta : 0.05
gamma : 0
colsample_bytree : 0.4
min_child_weight : 1
subsample : 1
===3 days===
AUC: 0.986321599215492
Accuracy: 0.794499449944995
eta : c(0.05, 0.05, 0.05)
max_depth : c(4, 6, 8)
gamma : c(0, 0, 0)
colsample_bytree : c(0.4, 0.4, 0.4)
min_child_weight : c(1, 1, 1)
subsample : c(1, 1, 1)
nrounds : c(100, 100, 100)
logLoss : c(2.4, 2.4, 2.4)
logLossSD : c(NA, NA, NA)
nrounds : 100
max_depth : 4
eta : 0.05
gamma : 0
colsample_bytree : 0.4
min_child_weight : 1
subsample : 1
===trainControl===
method : repeatedcv
number : 1
repeats : 1
search : random
p : 0.75
initialWindow : NULL
horizon : 1
fixedWindow : TRUE
skip : 0
verboseIter : TRUE
returnData : TRUE
returnResamp : final
savePredictions : FALSE
classProbs : TRUE
summaryFunction : function (data, lev = NULL, model = NULL) 
{
    if (is.null(lev)) 
        stop("'lev' cannot be NULL")
    if (!all(lev %in% colnames(data))) 
        stop("'data' should have columns consistent with 'lev'")
    if (!all(sort(lev) %in% sort(levels(data$obs)))) 
        stop("'data$obs' should have levels consistent with 'lev'")
    dataComplete <- data[complete.cases(data), ]
    probs <- as.matrix(dataComplete[, lev, drop = FALSE])
    logLoss <- ModelMetrics::mlogLoss(dataComplete$obs, probs)
    c(logLoss = logLoss)
}
selectionFunction : tolerance
preProcOptions : list(thresh = 0.95, ICAcomp = 3, k = 5, freqCut = 19, uniqueCut = 10, cutoff = 0.9)
sampling : NULL
index : NULL
indexOut : NULL
indexFinal : NULL
timingSamps : 0
predictionBounds : c(FALSE, FALSE)
seeds : NA
adaptive : list(min = 5, alpha = 0.05, method = "gls", complete = TRUE)
trim : FALSE
allowParallel : TRUE
===tuneGrid===
nrounds : c(100, 100, 100)
max_depth : c(4, 6, 8)
eta : c(0.05, 0.05, 0.05)
gamma : c(0, 0, 0)
colsample_bytree : c(0.4, 0.4, 0.4)
min_child_weight : c(1, 1, 1)
subsample : c(1, 1, 1)
