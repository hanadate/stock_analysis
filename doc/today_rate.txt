"X1" "X2" "X3"
"PreD" "1" "3" "5"
"XLK*" "0.16" "0.04" "0.09"
"XLF*" "0.05" "0.04" "0.11"
"XLE*" "0.07" "0.26" "0.28"
"XLB-" "0.08" "0.02" "0.10"
"XLI-" "0.06" "0.08" "0.07"
"XLY-" "0.17" "0.04" "0.06"
"XLV*" "0.05" "0.02" "0.03"
"XLP-" "0.05" "0.04" "0.02"
"XLU-" "0.14" "0.25" "0.06"
"TLT*" "0.13" "0.19" "0.15"
"zero" "0.04" "0.02" "0.04"

Tech XLK x3= TECL
Fin  XLF x3= FAS
Ind  XLI
Bas  XLB
Cons XLY
Ene  XLE x2= ERX
Heal XLV x3= CURE
Util XLU
Stap XLP
Trea TLT x3= RMF
Zero zero
# Note: Sell fast Leveraged ETFs. It must decay in a long term.

START: 2024-12-03 06:05:08
END: 2024-12-03 17:58:06
MIN DATE: 2006-12-01
MAX DATE: 2024-12-02
DIM: 4530x4579
===1 days===
AUC: 0.974459625505694
Accuracy: 0.703687348200486
eta : c(0.05, 0.05, 0.05, 0.05, 0.05, 0.05)
max_depth : c(4, 4, 6, 6, 8, 8)
gamma : c(0, 0, 0, 0, 0, 0)
colsample_bytree : c(0.4, 0.7, 0.4, 0.7, 0.4, 0.7)
min_child_weight : c(1, 1, 1, 1, 1, 1)
subsample : c(1, 1, 1, 1, 1, 1)
nrounds : c(100, 100, 100, 100, 100, 100)
logLoss : c(2.31, 2.31, 2.32, 2.32, 2.35, 2.36)
logLossSD : c(0.01, 0.01, 0.01, 0.01, 0.01, 0.01)
nrounds : 100
max_depth : 4
eta : 0.05
gamma : 0
colsample_bytree : 0.4
min_child_weight : 1
subsample : 1
===3 days===
AUC: 0.999998984347928
Accuracy: 0.997791031588248
eta : c(0.05, 0.05, 0.05, 0.05, 0.05, 0.05)
max_depth : c(4, 4, 6, 6, 8, 8)
gamma : c(0, 0, 0, 0, 0, 0)
colsample_bytree : c(0.4, 0.7, 0.4, 0.7, 0.4, 0.7)
min_child_weight : c(1, 1, 1, 1, 1, 1)
subsample : c(1, 1, 1, 1, 1, 1)
nrounds : c(100, 100, 100, 100, 100, 100)
logLoss : c(2.06, 2.06, 1.94, 1.95, 1.89, 1.9)
logLossSD : c(0.02, 0.02, 0.02, 0.02, 0.01, 0.02)
nrounds : 100
max_depth : 8
eta : 0.05
gamma : 0
colsample_bytree : 0.4
min_child_weight : 1
subsample : 1
===5 days===
AUC: 0.999999880551575
Accuracy: 0.999116022099447
eta : c(0.05, 0.05, 0.05, 0.05, 0.05, 0.05)
max_depth : c(4, 4, 6, 6, 8, 8)
gamma : c(0, 0, 0, 0, 0, 0)
colsample_bytree : c(0.4, 0.7, 0.4, 0.7, 0.4, 0.7)
min_child_weight : c(1, 1, 1, 1, 1, 1)
subsample : c(1, 1, 1, 1, 1, 1)
nrounds : c(100, 100, 100, 100, 100, 100)
logLoss : c(1.86, 1.86, 1.69, 1.69, 1.62, 1.63)
logLossSD : c(0.02, 0.02, 0.03, 0.03, 0.04, 0.03)
nrounds : 100
max_depth : 8
eta : 0.05
gamma : 0
colsample_bytree : 0.4
min_child_weight : 1
subsample : 1
===trainControl===
method : repeatedcv
number : 3
repeats : 2
search : random
p : 0.75
initialWindow : NULL
horizon : 1
fixedWindow : TRUE
skip : 0
verboseIter : TRUE
returnData : TRUE
returnResamp : final
savePredictions : FALSE
classProbs : TRUE
summaryFunction : function (data, lev = NULL, model = NULL) 
{
    if (is.null(lev)) 
        stop("'lev' cannot be NULL")
    if (!all(lev %in% colnames(data))) 
        stop("'data' should have columns consistent with 'lev'")
    if (!all(sort(lev) %in% sort(levels(data$obs)))) 
        stop("'data$obs' should have levels consistent with 'lev'")
    dataComplete <- data[complete.cases(data), ]
    probs <- as.matrix(dataComplete[, lev, drop = FALSE])
    logLoss <- ModelMetrics::mlogLoss(dataComplete$obs, probs)
    c(logLoss = logLoss)
}
selectionFunction : tolerance
preProcOptions : list(thresh = 0.95, ICAcomp = 3, k = 5, freqCut = 19, uniqueCut = 10, cutoff = 0.9)
sampling : NULL
index : NULL
indexOut : NULL
indexFinal : NULL
timingSamps : 0
predictionBounds : c(FALSE, FALSE)
seeds : NA
adaptive : list(min = 5, alpha = 0.05, method = "gls", complete = TRUE)
trim : FALSE
allowParallel : TRUE
===tuneGrid===
nrounds : c(100, 100, 100, 100, 100, 100)
max_depth : c(4, 6, 8, 4, 6, 8)
eta : c(0.05, 0.05, 0.05, 0.05, 0.05, 0.05)
gamma : c(0, 0, 0, 0, 0, 0)
colsample_bytree : c(0.4, 0.4, 0.4, 0.7, 0.7, 0.7)
min_child_weight : c(1, 1, 1, 1, 1, 1)
subsample : c(1, 1, 1, 1, 1, 1)
