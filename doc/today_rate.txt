"X1" "X2" "X3"
"PreD" "2" "3" "4"
"XLK*" "0.27" "0.08" "0.11"
"XLF*" "0.06" "0.07" "0.06"
"XLE*" "0.13" "0.31" "0.36"
"XLB-" "0.07" "0.05" "0.06"
"XLI-" "0.05" "0.07" "0.07"
"XLY-" "0.06" "0.06" "0.04"
"XLV*" "0.03" "0.04" "0.05"
"XLP-" "0.11" "0.05" "0.03"
"XLU-" "0.12" "0.17" "0.15"
"TLT*" "0.09" "0.09" "0.04"
"zero" "0.02" "0.02" "0.03"

Tech XLK x3= TECL
Fin  XLF x3= FAS
Ind  XLI
Bas  XLB
Cons XLY
Ene  XLE x2= ERX
Heal XLV x3= CURE
Util XLU
Stap XLP
Trea TLT x3= RMF
Zero zero
# Note: Sell fast Leveraged ETFs. It must decay in a long term.

START: 2024-12-05 06:05:08
END: 2024-12-05 18:01:56
MIN DATE: 2006-12-01
MAX DATE: 2024-12-04
DIM: 4532x4579
===2 days===
AUC: 0.999556430689754
Accuracy: 0.955849889624724
eta : c(0.05, 0.05, 0.05, 0.05, 0.05, 0.05)
max_depth : c(4, 4, 6, 6, 8, 8)
gamma : c(0, 0, 0, 0, 0, 0)
colsample_bytree : c(0.4, 0.7, 0.4, 0.7, 0.4, 0.7)
min_child_weight : c(1, 1, 1, 1, 1, 1)
subsample : c(1, 1, 1, 1, 1, 1)
nrounds : c(100, 100, 100, 100, 100, 100)
logLoss : c(2.2, 2.2, 2.15, 2.15, 2.13, 2.14)
logLossSD : c(0.01, 0.01, 0.01, 0.01, 0.01, 0.01)
nrounds : 100
max_depth : 6
eta : 0.05
gamma : 0
colsample_bytree : 0.4
min_child_weight : 1
subsample : 1
===3 days===
AUC: 0.999998762476412
Accuracy: 0.99801280635902
eta : c(0.05, 0.05, 0.05, 0.05, 0.05, 0.05)
max_depth : c(4, 4, 6, 6, 8, 8)
gamma : c(0, 0, 0, 0, 0, 0)
colsample_bytree : c(0.4, 0.7, 0.4, 0.7, 0.4, 0.7)
min_child_weight : c(1, 1, 1, 1, 1, 1)
subsample : c(1, 1, 1, 1, 1, 1)
nrounds : c(100, 100, 100, 100, 100, 100)
logLoss : c(2.06, 2.07, 1.94, 1.95, 1.89, 1.91)
logLossSD : c(0.02, 0.02, 0.02, 0.02, 0.02, 0.02)
nrounds : 100
max_depth : 8
eta : 0.05
gamma : 0
colsample_bytree : 0.4
min_child_weight : 1
subsample : 1
===4 days===
AUC: 0.999999037762188
Accuracy: 0.997791519434629
eta : c(0.05, 0.05, 0.05, 0.05, 0.05, 0.05)
max_depth : c(4, 4, 6, 6, 8, 8)
gamma : c(0, 0, 0, 0, 0, 0)
colsample_bytree : c(0.4, 0.7, 0.4, 0.7, 0.4, 0.7)
min_child_weight : c(1, 1, 1, 1, 1, 1)
subsample : c(1, 1, 1, 1, 1, 1)
nrounds : c(100, 100, 100, 100, 100, 100)
logLoss : c(1.96, 1.96, 1.83, 1.83, 1.78, 1.78)
logLossSD : c(0.02, 0.02, 0.02, 0.02, 0.02, 0.03)
nrounds : 100
max_depth : 8
eta : 0.05
gamma : 0
colsample_bytree : 0.4
min_child_weight : 1
subsample : 1
===trainControl===
method : repeatedcv
number : 3
repeats : 2
search : random
p : 0.75
initialWindow : NULL
horizon : 1
fixedWindow : TRUE
skip : 0
verboseIter : TRUE
returnData : TRUE
returnResamp : final
savePredictions : FALSE
classProbs : TRUE
summaryFunction : function (data, lev = NULL, model = NULL) 
{
    if (is.null(lev)) 
        stop("'lev' cannot be NULL")
    if (!all(lev %in% colnames(data))) 
        stop("'data' should have columns consistent with 'lev'")
    if (!all(sort(lev) %in% sort(levels(data$obs)))) 
        stop("'data$obs' should have levels consistent with 'lev'")
    dataComplete <- data[complete.cases(data), ]
    probs <- as.matrix(dataComplete[, lev, drop = FALSE])
    logLoss <- ModelMetrics::mlogLoss(dataComplete$obs, probs)
    c(logLoss = logLoss)
}
selectionFunction : tolerance
preProcOptions : list(thresh = 0.95, ICAcomp = 3, k = 5, freqCut = 19, uniqueCut = 10, cutoff = 0.9)
sampling : NULL
index : NULL
indexOut : NULL
indexFinal : NULL
timingSamps : 0
predictionBounds : c(FALSE, FALSE)
seeds : NA
adaptive : list(min = 5, alpha = 0.05, method = "gls", complete = TRUE)
trim : FALSE
allowParallel : TRUE
===tuneGrid===
nrounds : c(100, 100, 100, 100, 100, 100)
max_depth : c(4, 6, 8, 4, 6, 8)
eta : c(0.05, 0.05, 0.05, 0.05, 0.05, 0.05)
gamma : c(0, 0, 0, 0, 0, 0)
colsample_bytree : c(0.4, 0.4, 0.4, 0.7, 0.7, 0.7)
min_child_weight : c(1, 1, 1, 1, 1, 1)
subsample : c(1, 1, 1, 1, 1, 1)
